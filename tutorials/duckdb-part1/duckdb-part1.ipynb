{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45bc5972",
   "metadata": {},
   "source": [
    "# Using DuckDB to query the OBIS full export - Part 1\n",
    "\n",
    "## The OBIS full export\n",
    "\n",
    "OBIS has more than 160 million occurrence records available (and growing!). Previously you could download the [full export](https://obis.org/data/access/) as a single Parquet file and do a range of analysis with it, but since recently the full export [became available in AWS](https://github.com/iobis/obis-open-data) through the [Open Data Program](https://aws.amazon.com/opendata/). This came with a total update of the way the data is offered. Now the full export is offered as a dataset of [GeoParquet](https://geoparquet.org/) files, what opens up a world of possibilities in doing spatial analysis with the data, and also make analysis much more efficient and cloud performant. This new version also contains all measurements of the [eMoF extension](https://manual.obis.org/data_format.html#extendedmeasurementorfact-extension-emof).\n",
    "\n",
    "There are two ways you can access this dataset: download it locally or access directly from the AWS bucket. In both cases, we need the right tools to work with it. So, let's dive in this three parts tutorial. On the first part we will talk about [**DuckDB**](https://duckdb.org/), and how to do basic SQL queries. On the second part we will check the spatial capabilities of DuckDB. Finally, on the third part we will explore duckplyr, an R package that brings the tidyverse grammar to work with DuckDB on R.\n",
    "\n",
    "## A quick word about GeoParquets\n",
    "\n",
    "We already talked about Parquet and its many benefits in a previous tutorial. [GeoParquet](https://geoparquet.org/) extends the core Parquet to efficiently store and query geospatial vector data. It adds a geometry column, and some geospatial metadata to the file. It means that we can very quickly filter data that is on a certain region, for example.\n",
    "\n",
    "## And what is DuckDB?\n",
    "\n",
    "[DuckDB](https://duckdb.org/) is a lightweight SQL database designed for analytics. It makes it easy to query large files like CSVs or Parquet, and can speed up your analytical workflow. DuckDB have APIs for many languages, including R and Python.\n",
    "\n",
    "To use DuckDB you need to learn SQL (Structured Query Language), the standard language used to work with databases. There are many versions of the SQL language, depending on the management system you are dealing with (e.g. MySQL, PostgreSQL, etc.), and DuckDB also has its own version, which you can learn in [their documentation](https://duckdb.org/docs/stable/sql/introduction). **We will not go in depth on the SQL language, but just provide you with the basic commands to start!**\n",
    "\n",
    "### Essential SQL commands\n",
    "\n",
    "- SELECT: retrieves data from a table\n",
    "- FROM: which table to get the data from\n",
    "- WHERE: filters rows based on a condition\n",
    "- ORDER BY: sorts the results\n",
    "- LIMIT: restricts how many rows are returned\n",
    "- GROUP BY: groups rows so you can calculate things like sums, counts, or averages\n",
    "\n",
    "::: {.callout-note}\n",
    "Usually SQL commands are written on UPPERCASE, but that is not necessary for DuckDB calls - indeed, in our in-house code you will usually find all commands in lower case.\n",
    ":::\n",
    "\n",
    "## Let's do some analysis\n",
    "\n",
    "Ok, now that we have the basic knowledge of SQL, we can start exploring the OBIS full export. As we said, **you can access it directly from AWS**, but our experience shows that for normal internet connections, it is better to have a local copy instead. But to help you understand how you can access it directly from AWS, we will first show queries in another dataset, [the `speciesgrids`](https://github.com/iobis/speciesgrids), which provides a gridded version of all marine data in OBIS and GBIF.\n",
    "\n",
    "We will start by doing a very simple query - we will get the number of records for each species in the family [Acanthuridae](https://obis.org/taxon/125515). Just to prove that DuckDB is very fast, we will compare the same query done with the package [`arrow`](https://arrow.apache.org/docs/r/index.html).\n",
    "\n",
    "Since we are working with the online version of the **speciesgrids**, we will need to install a DuckDB extension. [Extensions](https://duckdb.org/docs/stable/extensions/overview) expand the capabilities of DuckDB, and are an amazing resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad52154",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "suppressPackageStartupMessages(library(arrow)) # For parquet queries\n",
    "suppressPackageStartupMessages(library(dplyr)) # For some analysis\n",
    "suppressPackageStartupMessages(library(duckdb)) # Our main package\n",
    "suppressPackageStartupMessages(library(tictoc)) # To get timings\n",
    "suppressPackageStartupMessages(library(glue)) # To easily make the queries text\n",
    "\n",
    "speciesgrids <- \"s3://obis-products/speciesgrids/h3_7\"\n",
    "\n",
    "# To work with DuckDB, we need to start by oppening a\n",
    "# connection to an in-memory database, using the DBI package\n",
    "con <- dbConnect(duckdb())\n",
    "\n",
    "# Install the httpfs extension\n",
    "dbSendQuery(con, \"install httpfs; load httpfs;\")\n",
    "\n",
    "# Let's check first with Arrow\n",
    "tic(\"arrow query\")\n",
    "ds <- open_dataset(speciesgrids)\n",
    "\n",
    "acanthuridae_counts_arrow <- ds |>\n",
    "    filter(family == \"Acanthuridae\") |>\n",
    "    group_by(AphiaID) |>\n",
    "    summarise(total_records = sum(records)) |>\n",
    "    collect() |>\n",
    "    arrange(desc(total_records))\n",
    "toc()\n",
    "\n",
    "# DuckDB query\n",
    "tic(\"DuckDB query\")\n",
    "acanthuridae_counts <- dbGetQuery(con, glue(\n",
    "    \"\n",
    "    SELECT AphiaID, SUM(records) AS total_records\n",
    "    FROM read_parquet('{speciesgrids}/*')\n",
    "    WHERE family = 'Acanthuridae'\n",
    "    GROUP BY AphiaID\n",
    "    ORDER BY total_records DESC;\n",
    "    \"\n",
    "))\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95087acf",
   "metadata": {},
   "source": [
    "Note that for DuckDB we had to add `/*` to the source (so it became `s3://obis-products/speciesgrids/h3_7/*`), telling that it should search all objects within that folder. \n",
    "\n",
    "The resulting object looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d57c7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Arrow version\n",
    "head(acanthuridae_counts_arrow, 3)\n",
    "\n",
    "# DuckDB version\n",
    "head(acanthuridae_counts, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a1d285",
   "metadata": {},
   "source": [
    "Now, for the **full export**. You can download it locally from the link available here: https://obis.org/data/access/\n",
    "\n",
    "::: {.callout-warning}\n",
    "This will be a big download, around 16GB. If you are running it on Google Colab, use the compact version which is available on our GitHub. Just run the first cell below to download it. If you download the full export locally, maybe you should mount your own drive to avoid downloading it every time you restart the notebook.\n",
    ":::\n",
    "\n",
    "We will again get the number of records by species on the Acanthuridae family. But this time, we will get it by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb59f4c8",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# FOR GOOGLE COLAB USE THIS:\n",
    "download.file(\n",
    "    \"https://raw.githubusercontent.com/iobis/resources/refs/heads/main/content/tutorials/duckdb-part1/compact_export1.zip\",\n",
    "    \"compact_export.zip\"\n",
    ")\n",
    "zip::unzip(\"compact_1.parquet.zip\", exdir = \"occurrence\")\n",
    "# And then use this as your full export path:\n",
    "fe_path <- \"occurrence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38eeece",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Put here the path to your downloaded full export\n",
    "full_export <- \"occurrence\"\n",
    "\n",
    "# DuckDB query\n",
    "tic(\"DuckDB query on full export\")\n",
    "acanthuridae_by_year <- dbGetQuery(con, glue(\n",
    "    \"\n",
    "    -- Here we use COUNT which will count all entries\n",
    "    -- and this is how you write SQL comments...\n",
    "    SELECT aphiaid AS AphiaID, date_year, COUNT(*) AS total_records\n",
    "    FROM read_parquet('{full_export}/*.parquet')\n",
    "    WHERE family = 'Acanthuridae'\n",
    "    GROUP BY aphiaid, date_year\n",
    "    ORDER BY total_records DESC;\n",
    "    \"\n",
    "))\n",
    "toc()\n",
    "\n",
    "# When we don't need the DuckDB connection anymore it is very important\n",
    "# to close it. After closing, if you need it again you should start from the\n",
    "# first step (dbConnect), and install the needed extensions.\n",
    "dbDisconnect(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c3cf04",
   "metadata": {},
   "source": [
    "Less than 2 seconds! That is really fast. Here is how the table looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ef4c88",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(acanthuridae_by_year, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04140446",
   "metadata": {},
   "source": [
    "\n",
    "Once you have it as an R object, you can then keep working with it. For example, we will get the three species with more records, do the cummulative sum of records and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9126e2b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "\n",
    "total_by_taxon <- acanthuridae_by_year |>\n",
    "    group_by(AphiaID) |>\n",
    "    summarise(records = sum(total_records)) |>\n",
    "    arrange(desc(records))\n",
    "\n",
    "top_species <- total_by_taxon$AphiaID[1:3]\n",
    "\n",
    "top_by_year <- acanthuridae_by_year |>\n",
    "    filter(AphiaID %in% top_species) |>\n",
    "    filter(!is.na(date_year)) |>\n",
    "    arrange(date_year) |>\n",
    "    group_by(AphiaID) |>\n",
    "    mutate(cumulative = cumsum(total_records)) |>\n",
    "    mutate(AphiaID = as.factor(AphiaID))\n",
    "\n",
    "ggplot(top_by_year) +\n",
    "    geom_line(aes(x = date_year, y = cumulative, color = AphiaID)) +\n",
    "    geom_point(aes(x = date_year, y = cumulative, color = AphiaID), alpha = .2) +\n",
    "    scale_color_manual(values = c(\"#0c54c7ff\", \"#e4710cff\", \"#0cc785ff\")) +\n",
    "    theme_light() +\n",
    "    ylab(\"Records\") + xlab(NULL) + ggtitle(\"Acanthuridae\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f834e",
   "metadata": {},
   "source": [
    "That is it, you already know the basics to work with DuckDB and improve your workflow when working with the Parquet exports from OBIS. On the next tutorial we will explore the spatial extension of DuckDB."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
