{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45bc5972",
   "metadata": {},
   "source": [
    "# Using DuckDB to query the OBIS full export - Part 2 (spatial extension)\n",
    "\n",
    "# Spatial extension of DuckDB\n",
    "\n",
    "In a previous tutorial we learned about **DuckDB** and how it can be used to query Parquet datasets from OBIS. As we shared, the new full export is a [GeoParquet](https://geoparquet.org/) dataset, meaning that it add spatial functionalities to the standard Parquet format. DuckDB has a powerful spatial extension, which we will present in this tutorial. Of course, we will just give you a glimpse of what you can do with this extension, and you should invest a few minutes to explore the [full documentation](https://duckdb.org/docs/stable/core_extensions/spatial/overview.html).\n",
    "\n",
    "Again, we will work with a local copy of the full export, which you can download from here: https://obis.org/data/access/.\n",
    "\n",
    ">NOTE:\n",
    ">This will be a big download, around 16GB. If you are running it on Google Colab, use the compact version which is available on our GitHub. Just run the first cell below to download it. If you download the full export locally, maybe you should mount your own drive to avoid downloading it every time you restart the notebook.\n",
    "\n",
    "We will get all records for the sea-urchin [_Paracentrotus lividus_](https://obis.org/taxon/124316) and the macroalgae [_Laminaria ochroleuca_](https://obis.org/taxon/145728) on a region in the coast of Portugal and Spain. We will use a WKT (Well-Known Text) representation of a polygon:\n",
    "\n",
    "`POLYGON ((-12.436523 35.817813, -3.999023 35.817813, -3.999023 44.465151, -12.436523 44.465151, -12.436523 35.817813))`\n",
    "\n",
    "You can check it on this nice website: https://wktmap.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45b1fad",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# FOR GOOGLE COLAB USE THIS:\n",
    "download.file(\n",
    "    \"https://github.com/iobis/resources/raw/refs/heads/main/content/tutorials/duckdb-part2/compact_2.parquet.zip\",\n",
    "    \"compact_export.zip\"\n",
    ")\n",
    "zip::unzip(\"compact_export.zip\", exdir = \"occurrence\")\n",
    "# And then use this as your full export path:\n",
    "fe_path <- \"occurrence\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6865819",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "suppressPackageStartupMessages(library(dplyr)) # For some analysis\n",
    "suppressPackageStartupMessages(library(duckdb)) # Our main package\n",
    "suppressPackageStartupMessages(library(tictoc)) # To get timings\n",
    "suppressPackageStartupMessages(library(glue)) # To easily make the queries text\n",
    "suppressPackageStartupMessages(library(sf)) # To later work with the spatial results\n",
    "suppressPackageStartupMessages(library(ggplot2)) # For plotting\n",
    "\n",
    "# To work with DuckDB, we need to start by oppening a\n",
    "# connection to an in-memory database, using the DBI package\n",
    "con <- dbConnect(duckdb())\n",
    "\n",
    "# Install the httpfs extension\n",
    "dbSendQuery(con, \"install spatial; load spatial;\")\n",
    "\n",
    "# Put here the path to your downloaded full export\n",
    "full_export <- \"/Volumes/OBIS2/obis_20250318_parquet/occurrence\"\n",
    "\n",
    "# Region:\n",
    "my_wkt <- \"POLYGON ((-12.436523 35.817813, -3.999023 35.817813, -3.999023 44.465151, -12.436523 44.465151, -12.436523 35.817813))\"\n",
    "\n",
    "species_id <- c(124316, 145728)\n",
    "\n",
    "# DuckDB query\n",
    "tic(\"DuckDB query on full export with spatial extension\")\n",
    "species_records <- dbGetQuery(con, glue(\n",
    "    \"\n",
    "    SELECT AphiaID, scientificName, date_year, occurrenceID, ST_AsText(geometry) AS geometry\n",
    "    FROM read_parquet('{full_export}/*.parquet')\n",
    "    WHERE\n",
    "        AphiaID IN ({paste(species_id, collapse = ', ')}) AND\n",
    "        -- ST_Intersects and ST_geometry are functions from the spatial extension\n",
    "        ST_Intersects (geometry, ST_GeomFromText('{my_wkt}'));\n",
    "    \"\n",
    "))\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a3e82c",
   "metadata": {},
   "source": [
    "And this is the resulting table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ad789c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(species_records, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21692a46",
   "metadata": {},
   "source": [
    "As you see, it contains a column `geometry` which is now converted to a WKT representation of the geometry. We can read it on R by using the `sf` package. Then we will plot it using `ggplot2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb164fc7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sp_records_sf <- st_as_sf(species_records, wkt = \"geometry\", crs = \"EPSG:4326\")\n",
    "\n",
    "# To add some context...\n",
    "selected_area <- st_as_sf(st_as_sfc(my_wkt, crs = 4326))\n",
    "world <- rnaturalearth::ne_countries(returnclass = \"sf\")\n",
    "sf_use_s2(FALSE)\n",
    "world <- suppressMessages(suppressWarnings(st_crop(world, selected_area)))\n",
    "\n",
    "ggplot() +\n",
    "    geom_sf(data = world, fill = \"grey90\") +\n",
    "    geom_sf(data = sp_records_sf, aes(color = scientificName), alpha = .5, size = 3) +\n",
    "    geom_sf(data = selected_area, color = \"blue\", fill = NA) +\n",
    "    theme_light()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aea2dd4",
   "metadata": {},
   "source": [
    "\n",
    "Now, let's consider a buffer around the selected area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424ae0f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# DuckDB query\n",
    "tic(\"Buffer query\")\n",
    "species_records_buff <- dbGetQuery(con, glue(\n",
    "    \"\n",
    "    SELECT AphiaID, scientificName, date_year, occurrenceID, ST_AsText(geometry) AS geometry\n",
    "    FROM read_parquet('{full_export}/*.parquet')\n",
    "    WHERE\n",
    "        AphiaID IN ({paste(species_id, collapse = ', ')}) AND\n",
    "        -- ST_Intersects and ST_geometry are functions from the spatial extension\n",
    "        ST_Intersects (geometry, ST_Buffer(ST_GeomFromText('{my_wkt}'), 10));\n",
    "        -- The distance of the buffer is expressed in degrees, that is, on the same unit of the CRS of the polygon\n",
    "    \"\n",
    "))\n",
    "toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f5a9d8",
   "metadata": {},
   "source": [
    "And this is the resulting table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f3377",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(species_records_buff, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9172c823",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sp_records_buff_sf <- st_as_sf(species_records_buff, wkt = \"geometry\", crs = \"EPSG:4326\")\n",
    "\n",
    "selected_area_buff <- suppressMessages(suppressWarnings(st_buffer(selected_area, dist = 10)))\n",
    "\n",
    "world <- rnaturalearth::ne_countries(returnclass = \"sf\")\n",
    "world <- suppressMessages(suppressWarnings(st_crop(world, selected_area_buff)))\n",
    "\n",
    "ggplot() +\n",
    "    geom_sf(data = world, fill = \"grey90\") +\n",
    "    geom_sf(data = sp_records_buff_sf, aes(color = scientificName), alpha = .5, size = 3) +\n",
    "    geom_sf(data = selected_area, color = \"blue\", fill = NA) +\n",
    "    geom_sf(data = selected_area_buff, color = \"green\", fill = NA) +\n",
    "    theme_light()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff8f0fd",
   "metadata": {},
   "source": [
    "Finally, let's get the convex hull over all records of each species. I will also retrieve all records, so I can plot together. Now that I'm doing my last query, I will also close the connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c262e771",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# DuckDB query\n",
    "tic(\"Convex hull query\")\n",
    "species_records_hull <- dbGetQuery(con, glue(\n",
    "    \"\n",
    "    SELECT \n",
    "        AphiaID,\n",
    "        scientificName,\n",
    "        ST_AsText(ST_ConvexHull(ST_Union_Agg(geometry))) AS convex_hull\n",
    "    FROM read_parquet('{full_export}/*.parquet')\n",
    "    WHERE\n",
    "        AphiaID IN ({paste(species_id, collapse = ', ')})\n",
    "    GROUP BY AphiaID, scientificName\n",
    "    \"\n",
    "))\n",
    "toc()\n",
    "\n",
    "tic(\"All records query\")\n",
    "species_records_all <- dbGetQuery(con, glue(\n",
    "    \"\n",
    "    SELECT \n",
    "        AphiaID,\n",
    "        scientificName,\n",
    "        ST_AsText(geometry) AS geometry\n",
    "    FROM read_parquet('{full_export}/*.parquet')\n",
    "    WHERE\n",
    "        AphiaID IN ({paste(species_id, collapse = ', ')})\n",
    "    \"\n",
    "))\n",
    "toc()\n",
    "\n",
    "dbDisconnect(con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b8baa4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sp_hull <- st_as_sf(species_records_hull, wkt = \"convex_hull\", crs = \"EPSG:4326\")\n",
    "species_records_all <- st_as_sf(species_records_all, wkt = \"geometry\", crs = \"EPSG:4326\")\n",
    "\n",
    "world <- rnaturalearth::ne_countries(returnclass = \"sf\")\n",
    "world <- suppressMessages(suppressWarnings(st_crop(world, sp_hull)))\n",
    "\n",
    "ggplot() +\n",
    "    geom_sf(data = world, fill = \"grey90\") +\n",
    "    geom_sf(data = sp_hull, aes(color = scientificName), fill = NA) +\n",
    "    geom_sf(data = species_records_all, aes(color = scientificName), fill = NA) +\n",
    "    theme_light()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3defa",
   "metadata": {},
   "source": [
    "That is it, now you can work with the spatial extension of DuckDB! In the next tutorial we will explore the R package [`duckplyr`](https://duckplyr.tidyverse.org/index.html), a drop-in replacement for DuckDB on R which uses the `tidyverse` grammar.\n",
    "\n",
    "## Bonus: the DuckDB UI\n",
    "\n",
    "DuckDB also has a UI extension, which enables you to explore the data using a dashboard-like interface. You can check how it works [here](https://duckdb.org/2025/03/12/duckdb-ui.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
